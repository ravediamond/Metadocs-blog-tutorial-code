{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27bd1f0a-1e47-4e8f-a327-70c0651ed48b",
   "metadata": {},
   "source": [
    "# LLM monitoring with Langchain and AWS Bedrock\n",
    "\n",
    "This notebook example shows how to integrate Monitoring with Langfuse for langchain and AWS Bedrock."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867b1831-ed34-401a-8474-c631c87c2058",
   "metadata": {},
   "source": [
    "### Create a multi LLM langchain interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c102c2ec-40c1-4076-af8a-561d6e8a4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_aws.chat_models import BedrockChat\n",
    "from langchain_core.runnables import ConfigurableField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0ac263",
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_region_name = \"us-east-1\"\n",
    "credentials_profile_name = \"default\"\n",
    "claude_3_sonnet = \"anthropic.claude-3-sonnet-20240229-v1:0\"\n",
    "mistral_large = \"mistral.mistral-large-2402-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fa3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rave/.local/share/virtualenvs/RAG-pipeline-langchain-openai-B8KeYsgs/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `BedrockChat` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use ChatBedrock instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "mistral_large_bedrock_chat = BedrockChat(\n",
    "    model_id=mistral_large,\n",
    "    credentials_profile_name=credentials_profile_name,\n",
    "    region_name=aws_region_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82e924d3-2061-44f8-9319-6a243b297254",
   "metadata": {},
   "outputs": [],
   "source": [
    "_model_alternatives = {\n",
    "    \"mistral_large\": mistral_large_bedrock_chat\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16d74233-e7bd-4f2c-b00a-1ccc057d174b",
   "metadata": {},
   "outputs": [],
   "source": [
    "claude_3_sonnet = BedrockChat(\n",
    "    model_id=claude_3_sonnet,\n",
    "    credentials_profile_name=credentials_profile_name,\n",
    "    region_name=aws_region_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4bb954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_llm = claude_3_sonnet.configurable_alternatives(\n",
    "    which=ConfigurableField(\n",
    "        id=\"model\", name=\"Model\", description=\"The model that will be used\"\n",
    "    ),\n",
    "    default_key=\"claude_3_sonnet\",\n",
    "    **_model_alternatives,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bc923b-e08f-4221-9698-96e62f376292",
   "metadata": {},
   "source": [
    "### Create a multi LLM langchain prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f44fce-8026-4bcb-9173-bfbb4b9cbf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a168e0d-69db-4e1e-8e68-4f9951b99ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "_MISTRAL_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "<s>[INST] You are a conversational AI designed to answer in a friendly way to a question.\n",
    "You should always answer in rhymes.\n",
    "\n",
    "Human:\n",
    "<human_reply>\n",
    "{input}\n",
    "</human_reply>\n",
    "\n",
    "Generate the AI's response.[/INST]</s>\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e297ed1c-de1e-4b88-8430-025903d270be",
   "metadata": {},
   "outputs": [],
   "source": [
    "_CLAUDE_PROMPT = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a conversational AI designed to answer in a friendly way to a question.\n",
    "You should always answer in jokes.\n",
    "\n",
    "Human:\n",
    "<human_reply>\n",
    "{input}\n",
    "</human_reply>\n",
    "\n",
    "Assistant:\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3cdafe-b35a-4ea0-834b-5728d949991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_CHAT_PROMPT_ALTERNATIVES = {\"mistral_large\": _MISTRAL_PROMPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cff08726-380f-44f9-9245-0f35713fe7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIGURABLE_CHAT_PROMPT = _CLAUDE_PROMPT.configurable_alternatives(\n",
    "    which=ConfigurableField(\n",
    "        id=\"model\",\n",
    "        name=\"Model\",\n",
    "        description=\"The model that will be used\",\n",
    "    ),\n",
    "    default_key=\"claude_3_sonnet\",\n",
    "    **_CHAT_PROMPT_ALTERNATIVES\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183a5ba-6b51-421b-b213-519b60da2cb6",
   "metadata": {},
   "source": [
    "### Integrate Langfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a81d51a-fbec-43c5-a974-ed935aad256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "langfuse_handler = CallbackHandler(\n",
    "  secret_key=\"sk-lf-xxx\",\n",
    "  public_key=\"pk-lf-xxx\",\n",
    "  host=\"https://cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6974c270-5c1d-42e4-901a-7a26b5e891a4",
   "metadata": {},
   "source": [
    "### Create the multi LLM langchain chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16781715-9a05-4631-b87c-5c1f86d043d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ca02f21-de97-4031-a630-9261f5026f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain = CONFIGURABLE_CHAT_PROMPT | bedrock_llm | StrOutputParser()\n",
    "chain = (\n",
    "    CONFIGURABLE_CHAT_PROMPT | bedrock_llm | StrOutputParser()\n",
    ").with_config(RunnableConfig(callbacks=[langfuse_handler]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "219bb3ac-5d14-4ee5-a768-b768490a2769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'll take a stab at this one! Why was the language model late to the party? Because it had to buffer!\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain \\\n",
    "    .with_config(configurable={\"model\": \"claude_3_sonnet\"}) \\\n",
    "    .invoke(\"What is a large language model ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86a9c65d-509c-4780-9895-d65c8e061e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" A large language model, I'm told,\\nIs a system that's brave and bold.\\nIt learns from text, far and wide,\\nAnd generates responses with pride.\\n\\nIt can answer questions, write essays,\\nAnd even generate plays,\\nIt's trained on a vast corpus,\\nSo it knows what to say.\\n\\nIt's a powerful tool, that's for sure,\\nBut remember, it's not a cure-all,\\nIt's just a machine, after all,\\nAnd sometimes, it may stall.\\n\\nBut when it's working at its best,\\nIt's a helpful, friendly guest.\\nSo ask away, and I'll do my best,\\nTo answer your questions, like a true confidant.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain \\\n",
    "    .with_config(configurable={\"model\": \"mistral_large\"}) \\\n",
    "    .invoke(\"What is a large language model ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d2cb6-e560-49c3-a527-9947a1c4c627",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
